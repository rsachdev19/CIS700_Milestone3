{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RTasmaUQsnX"
   },
   "source": [
    "# Milestone2\n",
    "\n",
    "Stephanie Eordanidis.\n",
    "Ravjot Sachdev,\n",
    "Jackson Taber\n",
    "\n",
    "Syracuse University : College of Engineering & Computer Science\n",
    "\n",
    "223 Link Hall, Syracuse, NY 13244\n",
    "\n",
    "sleordan@syr.edu, rssachde@syr.edu, jrtaber@syr.edu\n",
    "\n",
    "CIS 700 Machine Learning and Security\n",
    "\n",
    "05/12/2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2saP1Da3Qsnf"
   },
   "source": [
    "## Theme:\n",
    " “Adversarial Text Generation: Adversarial Machine Learning Applications in Text Analysis”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M443L_l7Qsng"
   },
   "source": [
    "## Purpose:\n",
    "The purpose of this lab is to add three new GAN models to the project space and successfully run them on the chosen dataset to generate synthetic data using an existing GAN project framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bsrl-QKhQsnh"
   },
   "source": [
    "## Project:\n",
    "Texygen is the name of the project selected. This project is a benchmarking tool that aids in text generation model research and testing. This tool allows for ease of various model testing to compare accuracy and synthetic data generation of models using same training baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmXaOJ8AQsni"
   },
   "source": [
    "## (Hard/Soft)ware:\n",
    "**Google Colaboratory**\t\thttps://colab.research.google.com/\n",
    "\n",
    "**GPU**                     Python 3 Google Compute Engine backend\n",
    "\n",
    "**Github**                  https://github.com/eordanis/CIS-700/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGtxblBCQsni"
   },
   "source": [
    "## Resources:\n",
    "**Original Source:** \t\thttps://github.com/geek-ai/Texygen\n",
    "\n",
    "**Modified Sources Acquired:** \t2SU Course Files Section -> Texygenmaster_Python_3.6.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kolVF4c9Qsnj"
   },
   "source": [
    "## Data:\n",
    "The data for the selected project is setup as follows:\n",
    "\n",
    "•\tGenerated data training: 5000 word and 20 sentence count\n",
    "\n",
    "•\tOracle data generation: 10,000 sentence generation\n",
    "\n",
    "•\tReal data training:\n",
    "        - image_coco : 20,000 sentences chosen from the image COCO captions data. 10,000 of which are used as training set while other 10,000 used as test set\n",
    "        - eapoe : 266 sentences chosen from the seinfeld script data. 133 of which are used as training set while other 133 used as test set\n",
    "                     Compiled from various Edgar Allan Po Poems found on referenced poem sight  [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnT5EoDoQsnk"
   },
   "source": [
    "## Modifications:\n",
    " To begin, the modified source code acquired from the 2SU application was further modified to combine the original intention of the origin source authors as well as professor modification. If no arguments are passed, all models/data are run.\n",
    " > **Note**: The order or model generation is done by first iterating over the GAN model type, then data type. If arguments are passed, those arguments will be validated and run accordingly to run a more targeted model test.\n",
    "\n",
    " Modifications were applied to eliminate much library warnings and informational messages as to keep output as clean as possible. File path naming was updated to be compliant with Google Colaboratory environment. All epoch time elapse console printing has been commented out for cleaner output reading.\n",
    "\n",
    " Additional modifications applied to this milestone were as follows:\n",
    " * Restructure of project for ease of use, updating of paths as needed\n",
    " * Redirect model output to the /save directory of the main project level instead of model level. Naming of output was also ensure to be unique\n",
    " * Three new GAN models were added to this project space\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlSdA9AHQsnk"
   },
   "source": [
    "## Setup:\n",
    "Due to the heft of processor/gpu usage, it was deemed necessary to run the project in the Google Colaboratory. Original attempt to run was done via Pycharm IDE Professional Edition with Anaconda derived environments, however this proved too great of a strain on the accessible workstation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8H8-PlvQsnk"
   },
   "source": [
    "### Step 1\n",
    "A new Google Colaboratory workspace was setup, titled “Milestone1”. This workspace was run using the hosted runtime environment. This document is the current document being read.\n",
    "\n",
    "In order to run against provided code base, it was necessary to sync the colab workspace the github repository files as follows\n",
    "\n",
    "```\n",
    "!git clone https://$GITHUB_AUTH@github.com/eordanis/CIS-700/\n",
    "%cd CIS-700\n",
    "```\n",
    "\n",
    "Running this command from the first cell in the workbook syncs the drive to the github repo location of project location,\n",
    "then we change directories to the CIS-700 level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jPNtvoeQsnl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://$GITHUB_AUTH@github.com/eordanis/CIS-700/\n",
    "%cd CIS-700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ-ge5jqQsno"
   },
   "source": [
    "### Step 2\n",
    "Now it was necessary to import and download any missing libraries the hosted colaborartoy runtime did not have readily available via the following commands:\n",
    "```\n",
    "            !pip install -r \"requirements.txt\"\n",
    "            import nltk\n",
    "            nltk.download('punkt')\n",
    "```\n",
    "Running this command from the next cell in the workbook installed the necessary libraries and at specified versions for the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MO2DlrxDQsno",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.19.0)\n",
      "Collecting tensorflow>=1.5.0\n",
      "  Using cached tensorflow-2.4.1-cp37-cp37m-win_amd64.whl (370.7 MB)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.4.1)\n",
      "Requirement already satisfied: nltk>=3.2.3 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (3.4.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\ravsa\\appdata\\roaming\\python\\python37\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.1)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\ravsa\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow>=1.5.0->-r requirements.txt (line 4)) (1.15.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.16.0-cp37-cp37m-win_amd64.whl (904 kB)\n",
      "Processing c:\\users\\ravsa\\appdata\\local\\pip\\cache\\wheels\\62\\76\\4c\\aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\\wrapt-1.12.1-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from tensorflow>=1.5.0->-r requirements.txt (line 4)) (3.7.4.3)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from tensorflow>=1.5.0->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\ravsa\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow>=1.5.0->-r requirements.txt (line 4)) (1.1.0)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (1.0.0)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.30.0-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (2.22.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (45.2.0.post20200210)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (2019.11.28)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (1.5.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ravsa\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.5.0->-r requirements.txt (line 4)) (2.2.0)\n",
      "Installing collected packages: keras-preprocessing, wheel, flatbuffers, protobuf, absl-py, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, tensorboard-plugin-wit, tensorboard-data-server, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, grpcio, tensorboard, astunparse, wrapt, tensorflow-estimator, google-pasta, gast, opt-einsum, tensorflow\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 cachetools-4.2.2 flatbuffers-1.12 gast-0.3.3 google-auth-1.30.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.16.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 wheel-0.36.2 wrapt-1.12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: astroid 2.3.3 requires typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\", which is not installed.\n",
      "ERROR: astroid 2.3.3 has requirement wrapt==1.11.*, but you'll have wrapt 1.12.1 which is incompatible.\n",
      "ERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.19.0 which is incompatible.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ravsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -r \"requirements.txt\"\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Rp_zaP5Qsnp"
   },
   "source": [
    "### Step 3\n",
    "Now it is time to run the application. Below are two examples of commands to run the application.\n",
    "```\n",
    "!python3 \"main.py\"\n",
    "```\n",
    "This first command was run without parameters. In the case of this command, all trainings (SeqGAN, Gsgan, TextganMmd, Leakgan, Rankgan, Maligan, Mle) were run on all available defaulted training data (oracle LSTM, real data, CFG). Running this command can take around 2+ hours to complete.\n",
    "\n",
    "```\n",
    "!python3 \"main.py\" -g seqgan -t real\n",
    "```\n",
    "\n",
    "This second command was run with parameters. In the case of this command, main was run with SeqGAN training on image_coco. Running targeted trainings take less time to run, on average completing in 5-15 minutes depending on selected parameters. With the above selection, runtime was run above 10 minutes.\n",
    "\n",
    "```\n",
    "!python3 \"main.py\" -g seqgan -t real  -d data/eapoe.txt\n",
    "```\n",
    "\n",
    "This third command was run with parameters. In the case of this command, main was run with SeqGAN training on eapoe. Running targeted trainings take less time to run, on average completing in 5-15 minutes depending on selected parameters. With the above selection, runtime was run above 10 minutes.\n",
    "\n",
    "> **NOTE:** For above estimates, based around 5 epochs. Additionally, CFG training appears to have stopped working suddenly, unsure why broken. Therefore running without that option for the time being. Additionally, the LeakGan model failed entirely to run now due to flag errors, so this model was discarded from testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9iJu3UIQsnp"
   },
   "source": [
    "## Process\n",
    "\n",
    "When running the various models, there are similar steps for each.\n",
    "1.\tBeginning Training – begin model training(s)\n",
    "2.\tSet training - sets the desired model training method\n",
    "3.\tStart model pre-train generator – uses the training data to pre-train the generator model\n",
    "4.\tStart model pre-train discriminator - – uses the training data to pre-train the discriminator model\n",
    "5.\tModel adversarial training – runs the model to generate results based on the test data and metrics applied\n",
    "6.\tFinish Training – end of model training(s)\n",
    "\n",
    "During training, each model training runs through several passes or epochs. For simplicity, base epoch is set to 5, with model training running thrice for 15 total epochs there abouts for each model trained on a particular data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Olz1GYmaQsnp"
   },
   "source": [
    "## Metrics\n",
    "\n",
    "**Abbreviations:**\n",
    "*   BLEU \t- BiLingual Evaluation Understudy\n",
    "*   GAN \t- Generative Adversarial Network\n",
    "*   NLL \t- Negative Log-Likelihood\n",
    "*   RL\t- Reinforcement Learning\n",
    "\n",
    "**Definitions**\n",
    "*   EmbSim – influenced by BLEU, used instead to compare the word embeddings vs BLEU’s comparison of word similarity between two sentences or documents.\n",
    "*   NLL-oracle : applied to synthetic data to determine fitting via oracle language model standards.\n",
    "*   NLL-test : dual to NLL-Oracle, used to determine a model’s capability to fit to real test data\n",
    "\n",
    "These measurement standards and more are discussed in the project directory’s “/docs/evaluation.md” location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbTurK39Qsnq"
   },
   "source": [
    "## Baseline Models\n",
    "\n",
    " For this report, the TextGAN and SeqGAN models were run on oracle and real training types in the previous project milestone and will be used as the baseline for new model comparisons. The real training types essentially runs the data against the image_coco.txt caption data. The TextGAN and SeqGAN was developed by the source project team to improve on existing GAN networks.\n",
    "\n",
    " With regards to TextGan, the goal of this model is to generate high quality realistic synthetic data while overcoming the convergence dilemma by using a generator that runs as a long short-term memory network and its discriminator a convolutional network. By matching high-dimension laten feature distributions of the testing and training data, this model over longer epochs has shown demonstrate a higher performance in quantitative evaluation, showing the TextGAN model can produce sentences that appear to have been written by a human, and not AI generated.\n",
    "\n",
    " For the SeqGAN model, this also proved successful in generating realistic looking sentences via this generator process. A second model was selected for comparison purposes. SeqGAN’s generator is based off the reinforcement learning stochastic policy, allowing SeqGAN to performing gradient policy update in order to circumvent differentiation issues in the generation. Its discriminator is run on complete sentences, and its results used as the reinforcement learning reward signal. According to source authors, this model boasted higher performance over others run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Models\n",
    "\n",
    "### **CGan** - Conditional Generative Adversarial Model\n",
    "\n",
    "### 2_GAN\n",
    "\n",
    "### 3_GAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkTxDWRTQsnq"
   },
   "source": [
    "## Testing\n",
    "\n",
    " Epochs were increased left to run at 5 for the sake of time. However, it is noted that as according to original project sourcing, >= 45 epochs for the models display the best NLL loss results on epochs > 40, prior to that point results would be poorer. NLL loss values are indicated to be better the lower they are, so if these values trend downward, the models are improving. For EmbeddedSimilarity, higher values are desired for better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQQn8V-8Qsnq"
   },
   "source": [
    "### CGAN\n",
    "The following commands are to run CGAN model on both oracle and real trainings.\n",
    "\n",
    "**NOTE:** The real data essentially trained the model on the eapoe.txt data.\n",
    "```\n",
    "!python3 \"main.py\" -g cgan -t oracle\n",
    "!python3 \"main.py\" -g cgan -t real\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0dEpH0EQsnr",
    "outputId": "67ff118d-c2d9-44a0-b6cc-673c11a51298",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Beginning Training ********\n",
      "set training\n",
      "oracle\n",
      "start pre-train generator:\n",
      "nll-oracle\n",
      "time elapsed of nll-oracle: 1.0739710330963135\n",
      "nll-test\n",
      "time elapsed of nll-test: 1.2133264541625977\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 88.22535681724548\n",
      "epoch:1\tnll-oracle:12.198931\tnll-test:40.538124\tEmbeddingSimilarity:-0.19819031171098683\t\n",
      "start pre-train discriminator:\n",
      "adversarial training:\n",
      "nll-oracle\n",
      "time elapsed of nll-oracle: 1.081681489944458\n",
      "nll-test\n",
      "time elapsed of nll-test: 1.2737576961517334\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 43.726564168930054\n",
      "epoch:6\tnll-oracle:11.897842\tnll-test:36.785576\tEmbeddingSimilarity:-0.309232358180863\t\n",
      "nll-oracle\n",
      "time elapsed of nll-oracle: 1.0407702922821045\n",
      "nll-test\n",
      "time elapsed of nll-test: 1.1645281314849854\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 43.738325357437134\n",
      "epoch:10\tnll-oracle:11.898141\tnll-test:36.8766\tEmbeddingSimilarity:-0.3125717377492794\t\n",
      "******** Completed Training ********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 \"main.py\" -g cgan -t oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvjMNcBLQsnr"
   },
   "source": [
    "####Oracle Output\n",
    "As we can see from the output above, over several loopthroughs, or epochs, the accuracy of the nll oracle and test values varied but appeared to having an upward trend in accuracy over epoch runs when running 1_GAN with oracle training. However, it is noted the embedded fell over time during the runs.\n",
    "For training, it would yield better results to run higher epochs, such as 40, however for testing sake only 5 were run.\n",
    "\n",
    "**Best Values**\n",
    "\n",
    "*   NLL-oracle:             11.898141             @epoch 10\n",
    "*   NLL-test:               36.785576             @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.198190311710986    @epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Hn4zHOuQsnr",
    "outputId": "bf9b38f2-e11f-4f05-a5cc-6c218acce3c2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Beginning Training ********\n",
      "set training\n",
      "real\n",
      "start pre-train generator:\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 44.0513916015625\n",
      "nll-test\n",
      "time elapsed of nll-test: 0.07195925712585449\n",
      "epoch:1\tEmbeddingSimilarity:-0.36917074786673465\tnll-test:37.6523\t\n",
      "start pre-train discriminator:\n",
      "adversarial training:\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 43.88083100318909\n",
      "nll-test\n",
      "time elapsed of nll-test: 0.013695955276489258\n",
      "epoch:6\tEmbeddingSimilarity:-0.3965602633631248\tnll-test:37.735287\t\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 43.74346661567688\n",
      "nll-test\n",
      "time elapsed of nll-test: 0.013765573501586914\n",
      "epoch:10\tEmbeddingSimilarity:-0.4435325866887675\tnll-test:37.640396\t\n",
      "******** Completed Training ********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 \"main.py\" -g cgan -t real -d data/eapoe.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecR1k-ptQsns"
   },
   "source": [
    "####Real Output\n",
    "As we can see from the output above, over several loopthroughs, or epochs, the accuracy of the nll values are also increase when running 1_GAN with real training. However, it is noted the embedded similarity fell over the course of the run. This indicates to us that the test_text.txt data generated should have closer similarity to the original eapoe.txt data file used to train the models.\n",
    "\n",
    "For training, it would yield better results to run higher epochs, such as 40, however for testing sake only 5 were run.\n",
    "\n",
    "**Best Values**\n",
    "\n",
    "*   NLL-test:               37.6404             @epoch 10\n",
    "*   EmbeddingSimilarity:    -0.369170747866734  @epoch 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYknSMAkQsns"
   },
   "source": [
    "### 2_GAN\n",
    "The following commands are to run 2_GAN model on both oracle and real trainings.\n",
    "\n",
    "> **NOTE:** The real data essentially trained the model on the eapoe.txt data.\n",
    "```\n",
    "!python3 \"main.py\" -g 2_GAN -t oracle\n",
    "!python3 \"main.py\" -g 2_GAN -t real\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XK9faFoQsnt",
    "outputId": "6d0ccf48-b7e1-4f7c-c47c-f4ec7fa06a51",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Beginning Training ********\n",
      "set training\n",
      "oracle\n",
      "start pre-train generator:\n",
      "nll-oracle\n",
      "time elapsed of nll-oracle: 1.0661637783050537\n",
      "nll-test\n",
      "time elapsed of nll-test: 1.1655919551849365\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 88.71221280097961\n",
      "epoch:1\tnll-oracle:10.742874\tnll-test:7.5933557\tEmbeddingSimilarity:-0.2093585259617846\t\n",
      "start pre-train discriminator:\n",
      "[1.5676435]\n",
      "[1.4180927]\n",
      "[1.3492159]\n",
      "[1.1821852]\n",
      "[1.1298636]\n",
      "[1.1436391]\n",
      "[1.2105415]\n",
      "[1.2776413]\n",
      "[1.2531519]\n",
      "[1.2658339]\n",
      "[1.2569084]\n",
      "[1.2460474]\n",
      "[1.2508906]\n",
      "[1.2178365]\n",
      "[1.1665254]\n",
      "adversarial training:\n",
      "nll-oracle\n",
      "time elapsed of nll-oracle: 1.042651653289795\n",
      "nll-test\n",
      "time elapsed of nll-test: 1.1159939765930176\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 44.104719400405884\n",
      "epoch:6\tnll-oracle:10.199376\tnll-test:7.031317\tEmbeddingSimilarity:-0.20886221700123014\t\n",
      "[1.1601384]\n",
      "[1.1915396]\n",
      "[1.1655589]\n",
      "[1.1938679]\n",
      "[1.2495728]\n",
      "[1.2036669]\n",
      "[1.2140615]\n",
      "[1.2339144]\n",
      "[1.214484]\n",
      "[1.1839753]\n",
      "[1.1693196]\n",
      "[1.1769569]\n",
      "[1.2049991]\n",
      "[1.147396]\n",
      "[1.1679164]\n",
      "[1.1675183]\n",
      "[1.1845496]\n",
      "[1.1699461]\n",
      "[1.1940631]\n",
      "[1.16613]\n",
      "[1.1838237]\n",
      "[1.150401]\n",
      "[1.1456553]\n",
      "[1.1730111]\n",
      "[1.1515791]\n",
      "[1.153158]\n",
      "[1.1934063]\n",
      "[1.1628721]\n",
      "[1.1556127]\n",
      "[1.1926014]\n",
      "[1.1529955]\n",
      "[1.1985537]\n",
      "[1.1184798]\n",
      "[1.1533136]\n",
      "[1.1328887]\n",
      "[1.1611487]\n",
      "[1.1126814]\n",
      "[1.158329]\n",
      "[1.1650071]\n",
      "[1.147441]\n",
      "[1.1489316]\n",
      "[1.2008834]\n",
      "[1.125101]\n",
      "[1.1751264]\n",
      "[1.1558373]\n",
      "[1.1373707]\n",
      "[1.1529287]\n",
      "[1.1284336]\n",
      "[1.1623422]\n",
      "[1.1521096]\n",
      "[1.1417301]\n",
      "[1.1652344]\n",
      "[1.1632206]\n",
      "[1.1339941]\n",
      "[1.1427692]\n",
      "[1.1198373]\n",
      "[1.1607592]\n",
      "[1.1749146]\n",
      "[1.139023]\n",
      "[1.1572973]\n",
      "[1.1513966]\n",
      "[1.1803614]\n",
      "[1.1468238]\n",
      "[1.1485491]\n",
      "[1.1740696]\n",
      "[1.163874]\n",
      "[1.1608914]\n",
      "[1.1689539]\n",
      "[1.1627896]\n",
      "[1.1202714]\n",
      "[1.1439091]\n",
      "[1.1762829]\n",
      "[1.1330371]\n",
      "[1.1709346]\n",
      "[1.1183212]\n",
      "[1.1331999]\n",
      "[1.131326]\n",
      "[1.14658]\n",
      "[1.1330512]\n",
      "[1.1391124]\n",
      "[1.1880605]\n",
      "[1.169145]\n",
      "[1.1596775]\n",
      "[1.1806759]\n",
      "[1.1498158]\n",
      "[1.1469805]\n",
      "[1.1416345]\n",
      "[1.1369095]\n",
      "[1.1483437]\n",
      "[1.1036606]\n",
      "[1.1386577]\n",
      "[1.1359184]\n",
      "[1.168629]\n",
      "[1.1826109]\n",
      "[1.1322566]\n",
      "[1.1093074]\n",
      "[1.1741802]\n",
      "[1.1341997]\n",
      "[1.1178846]\n",
      "[1.1513171]\n",
      "[1.1717126]\n",
      "[1.1748605]\n",
      "[1.1264043]\n",
      "[1.1462009]\n",
      "[1.1208065]\n",
      "[1.1813064]\n",
      "[1.1536645]\n",
      "[1.1254408]\n",
      "[1.156431]\n",
      "[1.1517853]\n",
      "[1.1714395]\n",
      "[1.1763394]\n",
      "[1.1220195]\n",
      "[1.1372112]\n",
      "[1.1249808]\n",
      "[1.1226155]\n",
      "[1.1273075]\n",
      "[1.1537614]\n",
      "[1.1127533]\n",
      "[1.1185256]\n",
      "[1.1375993]\n",
      "[1.1257644]\n",
      "[1.1086422]\n",
      "[1.1022162]\n",
      "[1.1170359]\n",
      "[1.124049]\n",
      "[1.090631]\n",
      "[1.1489662]\n",
      "[1.1530256]\n",
      "[1.159895]\n",
      "[1.1164427]\n",
      "[1.1524043]\n",
      "[1.1340841]\n",
      "[1.1213269]\n",
      "[1.0956577]\n",
      "[1.1078129]\n",
      "[1.1266901]\n",
      "[1.1329004]\n",
      "[1.17632]\n",
      "[1.126321]\n",
      "[1.0811216]\n",
      "[1.1534275]\n",
      "[1.1426201]\n",
      "[1.1118741]\n",
      "[1.1214416]\n",
      "[1.1120952]\n",
      "[1.1245064]\n",
      "[1.1232793]\n",
      "[1.0966082]\n",
      "[1.1318624]\n",
      "[1.1261961]\n",
      "[1.1505487]\n",
      "[1.1525217]\n",
      "[1.1369673]\n",
      "[1.1042455]\n",
      "[1.1554632]\n",
      "[1.1386197]\n",
      "[1.120192]\n",
      "[1.1861765]\n",
      "[1.1318724]\n",
      "[1.1422172]\n",
      "[1.1553296]\n",
      "[1.0975993]\n",
      "[1.1381533]\n",
      "[1.1184052]\n",
      "[1.1208136]\n",
      "[1.0989473]\n",
      "[1.119366]\n",
      "[1.1243013]\n",
      "[1.1337683]\n",
      "[1.1149342]\n",
      "[1.1236658]\n",
      "[1.1093526]\n",
      "[1.1792265]\n",
      "[1.1094102]\n",
      "[1.1196468]\n",
      "[1.131145]\n",
      "[1.1413236]\n",
      "[1.1303896]\n",
      "[1.1152273]\n",
      "nll-oracle\n",
      "time elapsed of nll-oracle: 1.058502197265625\n",
      "nll-test\n",
      "time elapsed of nll-test: 1.109898567199707\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 44.02372622489929\n",
      "epoch:10\tnll-oracle:10.114458\tnll-test:7.057727\tEmbeddingSimilarity:-0.2076366993211025\t\n",
      "[1.1107624]\n",
      "[1.1016937]\n",
      "[1.1715267]\n",
      "[1.1404303]\n",
      "[1.12575]\n",
      "[1.1616856]\n",
      "[1.106518]\n",
      "[1.1206733]\n",
      "[1.103158]\n",
      "[1.1128699]\n",
      "[1.174573]\n",
      "[1.1145554]\n",
      "[1.1416587]\n",
      "[1.1128533]\n",
      "[1.0752134]\n",
      "[1.1072524]\n",
      "[1.1055702]\n",
      "[1.119234]\n",
      "[1.1629769]\n",
      "[1.1405445]\n",
      "[1.1336107]\n",
      "[1.1113938]\n",
      "[1.1039513]\n",
      "[1.1347291]\n",
      "[1.1094075]\n",
      "[1.0934155]\n",
      "[1.0824243]\n",
      "[1.1122034]\n",
      "[1.0954107]\n",
      "[1.1336956]\n",
      "[1.121114]\n",
      "[1.1253678]\n",
      "[1.1208748]\n",
      "[1.101044]\n",
      "[1.1158596]\n",
      "[1.0967448]\n",
      "[1.1061422]\n",
      "[1.1203046]\n",
      "[1.1500388]\n",
      "[1.0674882]\n",
      "[1.1209037]\n",
      "[1.0578822]\n",
      "[1.0802932]\n",
      "[1.118731]\n",
      "[1.1066676]\n",
      "******** Completed Training ********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 \"main.py\" -g 2_GAN -t oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZQXB5V2Qsnt"
   },
   "source": [
    "#### Oracle Output\n",
    "As we can see from the output above, over several loopthroughs, or epochs, the accuracy of the nll oracle and test values varied but leaned toward improvment when running 2_GAN with oracle training. Additionally, it is noted the embedded similarity is improving as well.\n",
    "\n",
    "For training, it would yield better results to run higher epochs, such as 40, however for testing sake only 5 were run.\n",
    "\n",
    "**Best Values**\n",
    "\n",
    "*   NLL-oracle:             10.114458             @epoch 10\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvEehdQSQsnt",
    "outputId": "8c5d689e-d527-437c-ad66-bd4d7ba31695",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Beginning Training ********\n",
      "set training\n",
      "real\n",
      "start pre-train generator:\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 44.03479051589966\n",
      "nll-test\n",
      "time elapsed of nll-test: 0.06215381622314453\n",
      "epoch:1\tEmbeddingSimilarity:-1.092657517043026\tnll-test:6.101324\t\n",
      "start pre-train discriminator:\n",
      "[1.2007741]\n",
      "[1.0471132]\n",
      "[0.84945107]\n",
      "[0.8024252]\n",
      "[0.7262596]\n",
      "[0.65638715]\n",
      "[0.6189074]\n",
      "[0.7355596]\n",
      "[0.6026283]\n",
      "[0.5812113]\n",
      "[0.57940626]\n",
      "[0.57629865]\n",
      "[0.5636269]\n",
      "[0.6362342]\n",
      "[0.5192875]\n",
      "adversarial training:\n",
      "92.44891\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 44.07878828048706\n",
      "nll-test\n",
      "time elapsed of nll-test: 0.012879133224487305\n",
      "epoch:6\tEmbeddingSimilarity:-0.726695526133442\tnll-test:3.8079882\t\n",
      "[0.58081025]\n",
      "[0.5694416]\n",
      "[0.51506567]\n",
      "[0.5661042]\n",
      "[0.51280504]\n",
      "[0.5122116]\n",
      "[0.66419333]\n",
      "[0.58712816]\n",
      "[0.5099495]\n",
      "[0.5725429]\n",
      "[0.5087162]\n",
      "[0.50835705]\n",
      "[0.6621042]\n",
      "[0.50807506]\n",
      "[0.58020824]\n",
      "[0.57996696]\n",
      "[0.50685817]\n",
      "[0.5059252]\n",
      "[0.5775207]\n",
      "[0.56907755]\n",
      "[0.66619635]\n",
      "[0.59326375]\n",
      "[0.5045189]\n",
      "[0.58072263]\n",
      "[0.5043375]\n",
      "[0.56888807]\n",
      "[0.65353143]\n",
      "[0.5826941]\n",
      "[0.6519594]\n",
      "[0.5031161]\n",
      "[0.5025713]\n",
      "[0.5023833]\n",
      "[0.57921076]\n",
      "[0.5021084]\n",
      "[0.56858885]\n",
      "[0.5609347]\n",
      "[0.57676905]\n",
      "[0.5011923]\n",
      "[0.6284535]\n",
      "[0.56630063]\n",
      "[0.57564795]\n",
      "[0.50114673]\n",
      "[0.49996066]\n",
      "[0.5800075]\n",
      "[0.49995703]\n",
      "48.006817\n",
      "[0.5625898]\n",
      "[0.62222224]\n",
      "[0.4993542]\n",
      "[0.49984968]\n",
      "[0.49957004]\n",
      "[0.6177285]\n",
      "[0.56844497]\n",
      "[0.6362291]\n",
      "[0.49940014]\n",
      "[0.6404804]\n",
      "[0.49892384]\n",
      "[0.5685001]\n",
      "[0.49818152]\n",
      "[0.55588824]\n",
      "[0.49727914]\n",
      "[0.4972908]\n",
      "[0.547065]\n",
      "[0.49616563]\n",
      "[0.59668005]\n",
      "[0.5100902]\n",
      "[0.6529199]\n",
      "[0.59710234]\n",
      "[0.6173213]\n",
      "[0.5548835]\n",
      "[0.4961163]\n",
      "[0.49541125]\n",
      "[0.4949274]\n",
      "[0.5537586]\n",
      "[0.5611587]\n",
      "[0.49509907]\n",
      "[0.49378464]\n",
      "[0.6433846]\n",
      "[0.49403173]\n",
      "[0.49156526]\n",
      "[0.49166664]\n",
      "[0.49134922]\n",
      "[0.55423534]\n",
      "[0.5520719]\n",
      "[0.6058434]\n",
      "[0.4900672]\n",
      "[0.5430903]\n",
      "[0.54710275]\n",
      "[0.6096561]\n",
      "[0.5463486]\n",
      "[0.48980033]\n",
      "82.26557\n",
      "[0.53964823]\n",
      "[0.55880153]\n",
      "[0.48987585]\n",
      "[0.5516463]\n",
      "[0.4893579]\n",
      "[0.5983836]\n",
      "[0.54569525]\n",
      "[0.5404548]\n",
      "[0.4859194]\n",
      "[0.6041334]\n",
      "[0.58632296]\n",
      "[0.5293498]\n",
      "[0.4855577]\n",
      "[0.54662156]\n",
      "[0.5551339]\n",
      "[0.5243575]\n",
      "[0.5404824]\n",
      "[0.57689327]\n",
      "[0.52466327]\n",
      "[0.53600323]\n",
      "[0.48370975]\n",
      "[0.48280975]\n",
      "[0.548348]\n",
      "[0.675694]\n",
      "[0.52208406]\n",
      "[0.47959828]\n",
      "[0.5384036]\n",
      "[0.48011908]\n",
      "[0.5915868]\n",
      "[0.4780453]\n",
      "[0.47908694]\n",
      "[0.48883927]\n",
      "[0.52881676]\n",
      "[0.5300784]\n",
      "[0.5984587]\n",
      "[0.47545004]\n",
      "[0.47476244]\n",
      "[0.5877274]\n",
      "[0.56577045]\n",
      "[0.5384467]\n",
      "[0.5349601]\n",
      "[0.4742743]\n",
      "[0.5212701]\n",
      "[0.62110424]\n",
      "[0.5173534]\n",
      "89.982056\n",
      "[0.53744024]\n",
      "[0.5160001]\n",
      "[0.51819336]\n",
      "[0.47485247]\n",
      "[0.58027744]\n",
      "[0.5719464]\n",
      "[0.474527]\n",
      "[0.473625]\n",
      "[0.53485703]\n",
      "[0.5697412]\n",
      "[0.5412724]\n",
      "[0.5620461]\n",
      "[0.4705177]\n",
      "[0.46970767]\n",
      "[0.46824747]\n",
      "[0.47819677]\n",
      "[0.46606064]\n",
      "[0.465806]\n",
      "[0.5186194]\n",
      "[0.4656513]\n",
      "[0.46370742]\n",
      "[0.46205828]\n",
      "[0.55567247]\n",
      "[0.58204424]\n",
      "[0.45973945]\n",
      "[0.45857126]\n",
      "[0.4973126]\n",
      "[0.45722994]\n",
      "[0.5150454]\n",
      "[0.45606858]\n",
      "[0.4984514]\n",
      "[0.573463]\n",
      "[0.45331675]\n",
      "[0.509725]\n",
      "[0.45242402]\n",
      "[0.45241305]\n",
      "[0.50463134]\n",
      "[0.61163074]\n",
      "[0.4511859]\n",
      "[0.5183749]\n",
      "[0.5507725]\n",
      "[0.45120203]\n",
      "[0.45011976]\n",
      "[0.50170577]\n",
      "[0.49629027]\n",
      "55.982555\n",
      "EmbeddingSimilarity\n",
      "time elapsed of EmbeddingSimilarity: 43.626389265060425\n",
      "nll-test\n",
      "time elapsed of nll-test: 0.012568950653076172\n",
      "epoch:10\tEmbeddingSimilarity:-0.5105762563967318\tnll-test:3.4653516\t\n",
      "[0.50732607]\n",
      "[0.5751099]\n",
      "[0.50570905]\n",
      "[0.50560373]\n",
      "[0.6094849]\n",
      "[0.5293616]\n",
      "[0.4518996]\n",
      "[0.45132247]\n",
      "[0.4520904]\n",
      "[0.45270815]\n",
      "[0.5203265]\n",
      "[0.49941784]\n",
      "[0.45125765]\n",
      "[0.44897762]\n",
      "[0.55447197]\n",
      "[0.56228364]\n",
      "[0.44648334]\n",
      "[0.47851452]\n",
      "[0.45682627]\n",
      "[0.4954232]\n",
      "[0.44449374]\n",
      "[0.44542912]\n",
      "[0.44465768]\n",
      "[0.44320798]\n",
      "[0.5063447]\n",
      "[0.44055474]\n",
      "[0.4399815]\n",
      "[0.50267196]\n",
      "[0.49065533]\n",
      "[0.43783706]\n",
      "[0.43780363]\n",
      "[0.43552178]\n",
      "[0.4357171]\n",
      "[0.4892226]\n",
      "[0.48084238]\n",
      "[0.4989229]\n",
      "[0.4911862]\n",
      "[0.5509117]\n",
      "[0.43164423]\n",
      "[0.43102673]\n",
      "[0.47330785]\n",
      "[0.49580407]\n",
      "[0.43032095]\n",
      "[0.54535455]\n",
      "[0.43028036]\n",
      "******** Completed Training ********\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 \"main.py\" -g 2_GAN -t real -d data/eapoe.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTEmkScQQsnt"
   },
   "source": [
    "#### Real Output\n",
    "As we can see from the output above, over several loopthroughs, or epochs, the accuracy of the nll values are also increase when running 2_GAN with real training. Additionally, it is noted the embedded similarity is improving as well. This indicates to us that the test_text.txt data generated should have closer similarity to the original eapoe.txt data file used to train the models.\n",
    "\n",
    "For training, it would yield better results to run higher epochs, such as 40, however for testing sake only 5 were run.\n",
    "\n",
    "\n",
    "**Best Values**\n",
    "\n",
    "*   NLL-test:               3.4653516\t           @epoch 10\n",
    "*   EmbeddingSimilarity:    0.510576256396731  @epoch 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LS_GAN\n",
    "The following commands are to run 3_GAN model on both oracle and real trainings.\n",
    "\n",
    "> **NOTE:** The real data essentially trained the model on the eapoe.txt data.\n",
    "```\n",
    "!python3 \"main.py\" -g lsgan -t oracle\n",
    "!python3 \"main.py\" -g lsgan -t real\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python \"main.py\" -g lsgan -t oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oracle Output\n",
    "As we can see from the output above, over several loopthroughs, or epochs, the accuracy of the nll oracle and test values varied but leaned toward improvment when running 3_GAN with oracle training. Additionally, it is noted the embedded similarity is improving as well.\n",
    "\n",
    "For training, it would yield better results to run higher epochs, such as 40, however for testing sake only 5 were run.\n",
    "\n",
    "**Best Values**\n",
    "\n",
    "*   NLL-oracle:             10.114458             @epoch 10\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases.\n"
     ]
    }
   ],
   "source": [
    "!python3 \"main.py\" -g 3_GAN -t real -d data/eapoe.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real Output\n",
    "As we can see from the output above, over several loopthroughs, or epochs, the accuracy of the nll values are also increase when running 3_GAN with real training. Additionally, it is noted the embedded similarity is improving as well. This indicates to us that the test_text.txt data generated should have closer similarity to the original eapoe.txt data file used to train the models.\n",
    "\n",
    "For training, it would yield better results to run higher epochs, such as 40, however for testing sake only 5 were run.\n",
    "\n",
    "\n",
    "**Best Values**\n",
    "\n",
    "*   NLL-test:               3.4653516\t           @epoch 10\n",
    "*   EmbeddingSimilarity:    0.510576256396731  @epoch 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2szMid1RQsnu"
   },
   "source": [
    "### Data Comparision\n",
    "\n",
    "#### Oracle Data\n",
    " When comparing oracle data metrics between the two models baseline modes and three newly implemented models, the results are as follows:\n",
    "\n",
    "**TextGAN Best Values**\n",
    "\n",
    "*   NLL-oracle:             11.898141             @epoch 10\n",
    "*   NLL-test:               36.785576             @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.198190311710986    @epoch 1\n",
    "\n",
    "**SeqGAN Best Values**\n",
    "\n",
    "*   NLL-oracle:             10.114458             @epoch 10\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10\n",
    "\n",
    "**1_GAN Best Values**\n",
    "\n",
    "*   NLL-oracle:             10.114458             @epoch 10\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10\n",
    "\n",
    "**2_GAN Best Values**\n",
    "\n",
    "*   NLL-oracle:             10.114458             @epoch 10\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10\n",
    "\n",
    "**3_GAN Best Values**\n",
    "\n",
    "*   NLL-oracle:             10.114458             @epoch 10\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10\n",
    "\n",
    "#### Real Data\n",
    "When comparing real data metrics between the two models baseline modes and three newly implemented models, the results are as follows:\n",
    "\n",
    "**TextGAN Best Values**\n",
    "\n",
    "*   NLL-test:               37.6404             @epoch 10\n",
    "*   EmbeddingSimilarity:    -0.369170747866734  @epoch 1\n",
    "\n",
    "**SeqGAN Best Values**\n",
    "\n",
    "*   NLL-test:               3.4653516\t           @epoch 10\n",
    "*   EmbeddingSimilarity:    0.510576256396731  @epoch 10\n",
    "\n",
    "**1_GAN Best Values**\n",
    "\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10\n",
    "\n",
    "**2_GAN Best Values**\n",
    "\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10\n",
    "\n",
    "**3_GAN Best Values**\n",
    "\n",
    "*   NLL-test:               7.031317              @epoch 6\n",
    "*   EmbeddingSimilarity:    -0.207636699321102    @epoch 10\n",
    "\n",
    "Here we will take a look at the first 15 lines of the real data files, both training/test [eapoe.txt / test_eapoe.txt] and synthetic data generation from the model labeled test_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Representation\n",
    "This sections provides a more visual representation of results and comparative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "oracle_sg = pd.read_csv ('results/experiment-log-seqgan.csv')\n",
    "oracle_sg = oracle_sg.iloc[:, : 4]\n",
    "oracle_tg = pd.read_csv ('results/experiment-log-textgan.csv')\n",
    "oracle_tg = oracle_tg.iloc[:, : 4]\n",
    "real_sg = pd.read_csv ('results/experiment-log-seqgan-real.csv')\n",
    "real_sg = real_sg.iloc[:, : 3]\n",
    "real_tg = pd.read_csv ('results/experiment-log-textgan-real.csv')\n",
    "real_tg = real_tg.iloc[:, : 3]\n",
    "\n",
    "seqgan_data = pd.read_csv('results/textgan_test_file.txt', sep=\"\\n\", header=None)\n",
    "seqgan_data.columns = [\"Synthetic Generated Text - TextGAN          \"]\n",
    "textgan_data = pd.read_csv('results/seqgan_test_file.txt', sep=\"\\n\", header=None)\n",
    "textgan_data.columns = [\"Synthetic Generated Text - SeqGAN          \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SeqGan Oracle Experiment Data\n",
    "oracle_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TextGan Oracle Experiment Data\n",
    "oracle_tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SeqGan Real Experiment Data\n",
    "real_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TextGan Real Experiment Data\n",
    "real_tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SeqGan Real Synthetic Data\n",
    "seqgan_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TextGan Real Synthetic Data\n",
    "textgan_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create new dataframe to represent Oracle EmbeddingSimilarity across all models\n",
    "data = {'Epoch': [1,6,10],\n",
    "        'SeqGan': oracle_sg['EmbeddingSimilarity'],\n",
    "        'TextGan': oracle_tg['EmbeddingSimilarity'],\n",
    "        }\n",
    "df = pd.DataFrame(data)\n",
    "print('-----   Oracle EmbeddingSimilarites -----\\n')\n",
    "df.plot(x ='Epoch', y=['SeqGan', 'TextGan'], kind = 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Oracle EmbeddingSimilarity dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZoFeysDQsnw"
   },
   "source": [
    "## Notes\n",
    " This project was a collaborative effort by all team members listed in top of document. Project was developed/run/tested while on video call as a team effort. All parties put forth equal effort in testing, data selection and stripping, as well as understanding content.\n",
    "\n",
    " >**Note:** please refer to Team Project Documentation\\MileStone2\\Stephanie_Jackson_Ravjot_CIS700_M2_Contribution.txt for more contribution details\n",
    "\n",
    "Given the short duration of setup, running, etc there was not sufficient time to truly understand each of the models under the project. Two models from the previous milestone were used as the benchmark for comparison with the three newly incorporated models added with this milestone. However more time would be require for all encompassing tasking to really dive in and understand these models, and to run over longer epochs to see more concrete data results and comparisons. Additionally it should be noted the amount of time it takes to run these models with higher epoch values. Running the full models over and over can help training, however can take hours to complete. Furthermore, the .csv files were not populating. Given more time dedicate to this project, issues may have been able to be resolved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGfiU7ujQsnw"
   },
   "source": [
    "##Reference\n",
    "[1] Geek-Ai. “Texygen by Geek.AI.” GitHub, 2017, github.com/geek-ai/Texygen.\n",
    "\n",
    "[2] Yu, Lantao, et al. “SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient.” ArXiv.org, 25 Aug. 2017, arxiv.org/abs/1609.05473.\n",
    "\n",
    "[3] Zhang, Yizhe, et al. “Adversarial Feature Matching for Text Generation.” ArXiv.org, 18 Nov. 2017, arxiv.org/abs/1706.03850.\n",
    "\n",
    "[4] EA Poem Source.  https://poestories.com/read/valentine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9irmoejZQsnw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#PDF/HTML conversion of notebook\n",
    "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
    "!pip install pypandoc\n",
    "!jupyter nbconvert --to PDF \"main.ipynb\"\n",
    "!jupyter nbconvert --to HTML \"main.ipynb\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Milestone1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
